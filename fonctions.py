# fonctions.py

# Importations nÃ©cessaires
import os
import tensorflow as tf
from cityscapesscripts.helpers.labels import name2label
from cityscapesscripts.preparation.json2labelImg import json2labelImg
import json
import numpy as np
import albumentations as A
import cv2
from tensorflow.keras.utils import Sequence
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from albumentations import Compose, HorizontalFlip, Rotate, OneOf, RandomScale, Blur, GaussNoise, Resize
import matplotlib.pyplot as plt
from typing import List, Tuple
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate, Resizing, BatchNormalization, Dropout
from tensorflow.keras.models import Model
from tqdm import tqdm
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau, ModelCheckpoint
from cityscapesscripts.helpers.labels import trainId2label
import time
import segmentation_models as sm
import pandas as pd
from pathlib import Path
from datetime import datetime
from tensorflow.keras.optimizers import Adam
import glob


# DÃ©finition des classes utiles
CLASSES_UTILES = {
    "void": 0, "flat": 1, "construction": 2, "object": 3,
    "nature": 4, "sky": 5, "human": 6, "vehicle": 7
}

root_path = Path("C:/Users/icema/OpenClassrooms/AI_Engineer/venv8")
data_path = root_path / "data"
cityscapes_scripts_path = root_path / "notebooks/cityscapesScripts/cityscapesscripts"
images_path = data_path / "leftImg8bit"
masks_path = data_path / "gtFine"

def remap_classes(mask: np.ndarray) -> np.ndarray:
    """
    Convertit les classes Cityscapes originales (0-33) vers les 8 catÃ©gories principales dÃ©finies.

    Retourne un masque avec uniquement des valeurs de 0 Ã  7.
    """
    # DÃ©finition prÃ©cise du mapping basÃ© sur les "labelIds" Cityscapes originaux
    labelIds_to_main_classes = {
        0: 0,   # unlabeled â†’ void
        1: 0,   # ego vehicle â†’ void
        2: 0,   # rectification border â†’ void
        3: 0,   # out of roi â†’ void
        4: 0,   # static â†’ void
        5: 0,   # dynamic â†’ void
        6: 0,   # ground â†’ void
        7: 1,   # road â†’ flat
        8: 1,   # sidewalk â†’ flat
        9: 0,   # parking â†’ void
        10: 0,  # rail track â†’ void
        11: 2,  # building â†’ construction<
        12: 2,  # wall â†’ construction
        13: 2,  # fence â†’ construction
        14: 0,  # guard rail â†’ void
        15: 0,  # bridge â†’ void
        16: 0,  # tunnel â†’ void
        17: 3,  # pole â†’ object
        18: 3,  # polegroup â†’ object
        19: 3,  # traffic light â†’ object
        20: 3,  # traffic sign â†’ object
        21: 4,  # vegetation â†’ nature
        22: 4,  # terrain â†’ nature
        23: 5,  # sky â†’ sky
        24: 6,  # person â†’ human
        25: 6,  # rider â†’ human
        26: 7,  # car â†’ vehicle
        27: 7,  # truck â†’ vehicle
        28: 7,  # bus â†’ vehicle
        29: 7,  # caravan â†’ vehicle
        30: 7,  # trailer â†’ vehicle
        31: 7,  # train â†’ vehicle
        32: 7,  # motorcycle â†’ vehicle
        33: 7   # bicycle â†’ vehicle
    }

    # Appliquer le remapping prÃ©cis
    remapped_mask = np.copy(mask)
    for original_class, new_class in labelIds_to_main_classes.items():
        remapped_mask[mask == original_class] = new_class

    # Afficher les classes finales (vÃ©rification temporaire)
    # print(f"âœ… Valeurs uniques aprÃ¨s remapping : {np.unique(remapped_mask)}")

    return remapped_mask.astype(np.uint8)

def view_folder(dossier):
    dossier = Path(dossier)
    for sous_dossier in dossier.iterdir():
        if sous_dossier.is_dir():
            print(f"|-- {sous_dossier.name}")
            for sous_sous_dossier in sous_dossier.iterdir():
                if sous_sous_dossier.is_dir():
                    print(f"    |-- {sous_sous_dossier.name}")

def load_image(path: str, target_size: Tuple[int, int]) -> np.ndarray:
    """Charge et normalise une image entre 0 et 1."""
    img = load_img(path, target_size=target_size)
    return img_to_array(img).astype("float32") / 255.0

def load_mask(path: str, target_size: Tuple[int, int], mask_mode="labelIds") -> np.ndarray:
    """
    Charge, redimensionne et remappe un masque.
    Applique systÃ©matiquement le remapping vers les 8 classes principales.

    Args:
        path (str): Chemin vers le masque.
        target_size (Tuple[int, int]): Taille de sortie (hauteur, largeur).
        mask_mode (str): "labelIds" pour les masques Cityscapes originaux, "trainIds" sinon.

    Returns:
        np.ndarray: Masque avec valeurs de classe entre 0 et 7.
    """
    mask = load_img(path, target_size=target_size, color_mode="grayscale")
    mask = img_to_array(mask).astype("uint8").squeeze()

    # Toujours appliquer le remapping pour garantir 8 classes
    mask = remap_classes(mask)

    return mask

def one_hot_encode_mask(mask: np.ndarray, num_classes: int) -> np.ndarray:
    """Encode un masque en One-Hot."""

    # VÃ©rifier les valeurs uniques avant l'encodage
    unique_values = np.unique(mask)
    if np.any(unique_values >= num_classes):
        print(f"Attention : Certaines valeurs de masques dÃ©passent {num_classes-1}: {unique_values}")
        mask = np.clip(mask, 0, num_classes - 1)

    return np.eye(num_classes, dtype=np.uint8)[mask]

def decode_mask(mask: np.ndarray) -> np.ndarray:
    """Convertit un masque One-Hot en format indexÃ©."""
    return np.argmax(mask, axis=-1)

def get_augmentations(image_size: Tuple[int, int]) -> Compose:
    """DÃ©finit les transformations Albumentations pour l'entraÃ®nement."""
    return Compose([
        HorizontalFlip(p=0.2),
        Rotate(limit=15, p=0.2),
        RandomScale(scale_limit=0.1, p=0.2),
        Resize(*image_size, interpolation=cv2.INTER_NEAREST)
    ])

class DataGenerator(Sequence):
    def __init__(self, image_paths, mask_paths, image_size=(256, 256), batch_size=64, num_classes=8, # TEST avec 512x512, 1024x1024, 512x1024, 1024x512, 256x512 et 512x256
                shuffle=True, augmentation_ratio=1.0, use_cache=False):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.image_size = image_size
        self.batch_size = batch_size
        self.num_classes = num_classes
        self.shuffle = shuffle
        self.augmentation_ratio = augmentation_ratio
        self.use_cache = use_cache
        self.cache = {}  # Cache des masques transformÃ©s
        self.augmentation = get_augmentations(image_size)
        self.on_epoch_end()

    def __getitem__(self, index):
        start_time = time.time()
        start = index * self.batch_size
        end = start + self.batch_size
        batch_image_paths = self.image_paths[start:end]
        batch_mask_paths = self.mask_paths[start:end]

        batch_images, batch_masks = [], []

        for img_path, mask_path in zip(batch_image_paths, batch_mask_paths):
            img = load_image(img_path, self.image_size)

            if self.use_cache and mask_path in self.cache:
                mask = self.cache[mask_path]
            else:
                mask = load_mask(mask_path, self.image_size, mask_mode="trainIds")
                if self.use_cache:
                    self.cache[mask_path] = mask

            if np.random.rand() < self.augmentation_ratio:
                augmented = self.augmentation(image=img, mask=mask)
                img, mask = augmented["image"], augmented["mask"]

            batch_images.append(img)
            batch_masks.append(one_hot_encode_mask(mask, self.num_classes))

        elapsed_time = time.time() - start_time
        # print(f"ðŸ“Š GÃ©nÃ©ration batch {index} en {elapsed_time:.2f}s")

        return np.stack(batch_images), np.stack(batch_masks)

    def __len__(self):
        """Renvoie le nombre total de batches par epoch."""
        return int(np.ceil(len(self.image_paths) / self.batch_size))

    def on_epoch_end(self) -> None:
        """MÃ©lange les donnÃ©es aprÃ¨s chaque epoch si shuffle est activÃ©."""
        if self.shuffle:
            data = list(zip(self.image_paths, self.mask_paths))
            np.random.shuffle(data)
            self.image_paths, self.mask_paths = zip(*data)

    def visualize_batch(self, num_images: int = 5) -> None:
        """Affiche correctement un lot d'images et de masques."""
        batch_images, batch_masks = self.__getitem__(0)
        num_images = min(num_images, len(batch_images))
        fig, axes = plt.subplots(num_images, 2, figsize=(10, num_images * 5))

        for i in range(num_images):
            axes[i, 0].imshow(batch_images[i])
            axes[i, 0].set_title("Image")
            axes[i, 0].axis("off")

            axes[i, 1].imshow(decode_mask(batch_masks[i]), cmap="inferno")
            axes[i, 1].set_title("Mask (decoded)")
            axes[i, 1].axis("off")

        plt.tight_layout()
        plt.show()


# Test du DataGenerator
if __name__ == "__main__":
    train_gen = DataGenerator(
        image_paths=train_input_img_paths,
        mask_paths=train_label_ids_img_paths,
        image_size=(256, 256),  # TEST avec 512x512
        batch_size=64,  # TEST: 8, 16 ou 32
        num_classes=8,
        shuffle=True,
        augmentation_ratio=0.5
    )

    train_gen.visualize_batch(num_images=3)

    def on_epoch_end(self) -> None:
        """MÃ©lange les donnÃ©es aprÃ¨s chaque epoch si shuffle est activÃ©."""
        if self.shuffle:
            data = list(zip(self.image_paths, self.mask_paths))
            np.random.shuffle(data)
            self.image_paths, self.mask_paths = zip(*data)

    def visualize_batch(self, num_images: int = 5) -> None:
        """Affiche correctement un lot d'images et de masques."""
        batch_images, batch_masks = self.__getitem__(0)
        num_images = min(num_images, len(batch_images))
        fig, axes = plt.subplots(num_images, 2, figsize=(10, num_images * 5))

        for i in range(num_images):
            axes[i, 0].imshow(batch_images[i])
            axes[i, 0].set_title("Image")
            axes[i, 0].axis("off")

            axes[i, 1].imshow(decode_mask(batch_masks[i]), cmap="inferno")
            axes[i, 1].set_title("Mask (decoded)")
            axes[i, 1].axis("off")

        plt.tight_layout()
        plt.show()

def iou_coef(y_true, y_pred, smooth=1e-6):
    """
    Calcule l'Intersection over Union (IoU).
    Correction : conversion explicite en float32.
    """
    y_true = tf.keras.backend.cast(y_true, "float32")
    y_pred = tf.keras.backend.cast(y_pred, "float32")
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    """
    Calcule le Dice Coefficient.
    Correction : conversion explicite en float32.
    """
    y_true = tf.keras.backend.cast(y_true, "float32")
    y_pred = tf.keras.backend.cast(y_pred, "float32")
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)

def weighted_mean_iou(y_true, y_pred, num_classes=8, penalty_class=5, penalty_weight=3):
    """
    Calcule le Mean IoU avec une pÃ©nalitÃ© sur une classe spÃ©cifique (ex: "person").
    - penalty_class : indice de la classe Ã  pÃ©naliser (par dÃ©faut 5 = "person")
    - penalty_weight : coefficient de pondÃ©ration pour cette classe
    """
    iou_values = []
    for i in range(num_classes):
        iou = iou_coef(y_true[..., i], y_pred[..., i])
        if i == penalty_class:
            iou *= penalty_weight  # Appliquer la pondÃ©ration sur la classe "person"
        iou_values.append(iou)
    return tf.keras.backend.mean(tf.keras.backend.stack(iou_values))

def weighted_categorical_crossentropy(weights):
    """
    Fonction de perte pondÃ©rÃ©e pour accorder une pÃ©nalitÃ© plus Ã©levÃ©e Ã  certaines classes.

    Args:
        weights (np.array): Tableau des poids pour chaque classe.

    Returns:
        fonction perte utilisable avec model.compile()
    """
    def loss(y_true, y_pred):
        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)
        return -tf.reduce_sum(weights * y_true * tf.math.log(y_pred), axis=-1)
    return loss

    return loss

def mean_iou(y_true, y_pred, num_classes=8):
    """
    Fonction de mÃ©trique Mean IoU pour la segmentation multi-classes.
    """
    iou_values = []
    for i in range(num_classes):
        intersection = tf.reduce_sum(y_true[..., i] * y_pred[..., i])
        union = tf.reduce_sum(y_true[..., i]) + tf.reduce_sum(y_pred[..., i]) - intersection
        iou = (intersection + 1e-6) / (union + 1e-6)  # Ajout d'un epsilon pour Ã©viter la division par 0
        iou_values.append(iou)
    return tf.reduce_mean(iou_values)

def unet_mini(input_shape=(256, 256, 3), num_classes=8):
    """
    ModÃ¨le U-Net simplifiÃ© corrigÃ© pour la segmentation d'images multi-classes.
    Retourne le modÃ¨le U-Net mini compilÃ©.
    """
    inputs = Input(shape=input_shape)

    # Encodeur
    conv1 = Conv2D(32, (3, 3), activation="relu", padding="same")(inputs)
    conv1 = BatchNormalization()(conv1)
    conv1 = Conv2D(32, (3, 3), activation="relu", padding="same")(conv1)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D((2, 2))(conv1)  # 128x128

    conv2 = Conv2D(64, (3, 3), activation="relu", padding="same")(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Conv2D(64, (3, 3), activation="relu", padding="same")(conv2)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D((2, 2))(conv2)

    # Bottleneck (64x64 si input est 256x256)
    conv3 = Conv2D(128, (3, 3), activation="relu", padding="same")(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Dropout(0.3)(conv3)  # Dropout pour Ã©viter l'overfitting (0.4 a 0.6)
    conv3 = Conv2D(128, (3, 3), activation="relu", padding="same")(conv3)
    conv3 = BatchNormalization()(conv3)

    # DÃ©codeur
    up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding="same")(conv3)  # 64x64 vers 128x128
    up4 = Concatenate()([up4, conv2])
    conv4 = Conv2D(64, (3, 3), activation="relu", padding="same")(up4)
    conv4 = BatchNormalization()(conv4)

    up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding="same")(conv4)  # 128x128 â†’ 256x256
    up5 = Concatenate()([up5, conv1])
    conv5 = Conv2D(32, (3, 3), activation="relu", padding="same")(up5)
    conv5 = BatchNormalization()(conv5)

    # Couche de sortie Softmax
    outputs = Conv2D(num_classes, (1, 1), activation="softmax")(conv5)

    # CrÃ©ation du modÃ¨le
    model = Model(inputs, outputs=outputs, name="unet_mini")

    return model

def get_logger(nom_modele:str):
    """
    CrÃ©e un CSVLogger pour enregistrer les mÃ©triques d'entraÃ®nement dans un fichier horodatÃ©.

    Args:
        nom_modele (str): Nom du modÃ¨le utilisÃ© pour le nom du fichier.

    Returns:
        CSVLogger: callback pour enregistrer les logs.
    """
    logs_dir = Path("test_modele")
    logs_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = logs_dir / f"{nom_modele}_{timestamp}.csv"

    return CSVLogger(log_filename, separator=",", append=False)


def entrainer_modele(model,
                    train_generator,
                    val_generator,
                    epochs:int = 50,
                    patience:int = 5):
    """
    EntraÃ®ne le modÃ¨le avec arrÃªt anticipÃ©, ajustement dynamique du learning rate, sauvegarde du meilleur modÃ¨le, 
    sauvegarde automatique des mÃ©triques et des learning curves.

    Args:
        model (Model): ModÃ¨le Keras Ã  entraÃ®ner.
        train_generator (Sequence): GÃ©nÃ©rateur pour l'entraÃ®nement.
        val_generator (Sequence): GÃ©nÃ©rateur pour la validation.
        epochs (int): Nombre maximal d'Ã©poques.
        patience (int): Nombre d'Ã©poques sans amÃ©lioration avant arrÃªt anticipÃ©.

    Returns:
        history : L'historique d'entraÃ®nement Keras.
    """

    logs_dir = Path("test_modele")
    logs_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_filename = logs_dir / f"{model.name}_{timestamp}"

    # CSV Logger
    csv_logger = CSVLogger(f"{base_filename}.csv", separator=",", append=False)

    # Callback d'arrÃªt anticipÃ©
    early_stop = EarlyStopping(monitor="val_loss", patience=patience, restore_best_weights=True, verbose=1)

    # Callback de rÃ©duction du taux d'apprentissage
    reduce_lr = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=patience//2, verbose=1)

    # Callback de sauvegarde du meilleur modÃ¨le
    checkpoint = ModelCheckpoint(
        filepath=f"{base_filename}_best_model.keras",
        monitor="val_mean_iou",
        mode="max",
        save_best_only=True,
        verbose=1
    )

    debut_entrainement = time.time()

    history = model.fit(
        train_generator,
        epochs=epochs,
        validation_data=val_generator,
        callbacks=[csv_logger, early_stop, reduce_lr, checkpoint],
        verbose=1
    )

    temps_total = time.time() - debut_entrainement

    # Enregistrer le temps total d'entraÃ®nement
    df_metrics = pd.read_csv(f"{base_filename}.csv")
    df_metrics["temps_total_sec"] = temps_total
    df_metrics.to_csv(f"{base_filename}.csv", index=False)

    # GÃ©nÃ©ration des learning curves
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.plot(history.history["loss"], label="train_loss")
    plt.plot(history.history["val_loss"], label="val_loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Learning Curve (Loss)")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history["mean_iou"], label="train_mean_iou")
    plt.plot(history.history["val_mean_iou"], label="val_mean_iou")
    plt.xlabel("Epochs")
    plt.ylabel("Mean IoU")
    plt.title("Learning Curve (Mean IoU)")
    plt.legend()

    plt.tight_layout()
    plt.savefig(f"{base_filename}_learning_curves.png")
    plt.close()

    print(f"âœ… EntraÃ®nement terminÃ© en {temps_total:.2f} secondes.")
    print(f"ðŸ“Š MÃ©triques enregistrÃ©es dans : {base_filename}.csv")
    print(f"ðŸ“ˆ Learning curves enregistrÃ©es dans : {base_filename}_learning_curves.png")
    print(f"ðŸ“Œ Meilleur modÃ¨le sauvegardÃ© : {base_filename}_best_model.keras")

    return history

def unet_vgg16(input_shape=(256, 256, 3), num_classes=8, learning_rate=1e-4):
    """
    ModÃ¨le U-Net avec backbone VGG16 prÃ©-entraÃ®nÃ© sur ImageNet.
    """
    sm.set_framework("tf.keras")

    model = sm.Unet(
        backbone_name="vgg16",
        input_shape=input_shape,
        encoder_weights="imagenet",
        classes=num_classes,
        activation="softmax"
    )

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss="categorical_crossentropy",
        metrics=[mean_iou, dice_coef, "accuracy"]
    )

    model._name = "unet_vgg16"
    return model

def unet_resnet50(input_shape=(256, 256, 3), num_classes=8, learning_rate=1e-4):
    """
    ModÃ¨le U-Net avec backbone ResNet50 prÃ©-entraÃ®nÃ© sur ImageNet.
    """
    sm.set_framework("tf.keras")

    model = sm.Unet(
        backbone_name="resnet50",
        input_shape=input_shape,
        encoder_weights="imagenet",
        classes=num_classes,
        activation="softmax"
    )

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss="categorical_crossentropy",
        metrics=[mean_iou, dice_coef, "accuracy"]
    )

    model._name = "unet_resnet50"
    return model

def unet_efficientnetb3(input_shape=(512, 512, 3), num_classes=8, learning_rate=1e-4):
    """
    ModÃ¨le U-Net avec backbone EfficientNet-B3 prÃ©-entraÃ®nÃ© sur ImageNet.
    """
    sm.set_framework("tf.keras")

    model = sm.Unet(
        backbone_name="efficientnetb3",
        encoder_weights="imagenet",
        input_shape=input_shape,
        classes=num_classes,
        activation="softmax"
    )

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss=sm.losses.categorical_focal_jaccard_loss,
        metrics=[sm.metrics.iou_score, sm.metrics.FScore(), dice_coef]
    )

    model._name = "unet_efficientnetb3"
    return model

def charger_metriques(dossier_logs):
    """
    Charge tous les fichiers CSV de mÃ©triques prÃ©sents dans un dossier.

    Args:
        dossier_logs (str): Chemin vers le dossier contenant les fichiers CSV.

    Returns:
        dict: Dictionnaire avec nom du modÃ¨le en clÃ© et dataframe en valeur.
    """
    fichiers = glob.glob(os.path.join(dossier_logs, "*.csv"))
    resultats = {}

    for fichier in fichiers:
        # RÃ©cupÃ¨re le nom complet du modÃ¨le (par exemple unet_mini, unet_vgg16)
        nom_modele = "_".join(os.path.basename(fichier).split("_")[:-2])
        df = pd.read_csv(fichier)
        resultats[nom_modele] = df

    return resultats

def tracer_metriques(resultats):
    """
    Trace les mÃ©triques des diffÃ©rents modÃ¨les sur des graphiques.

    Args:
        resultats (dict): Dictionnaire avec nom modÃ¨le et dataframe.
    """

    # Palette de couleurs spÃ©cifique pour chaque modÃ¨le
    couleurs = {
        "mini": "blue",
        "vgg16": "green",
        "resnet50": "red",
        "efficientnetb3": "purple"
    }

    plt.figure(figsize=(18, 18))

    # Graphique de Loss (Perte)
    plt.subplot(3, 2, 1)
    for modele, df in resultats.items():
        couleur = couleurs.get(modele, "black")
        plt.plot(df["loss"], label=f"{modele} Train Loss", color=couleur, linestyle="--")
        plt.plot(df["val_loss"], label=f"{modele} Val Loss", color=couleur, linestyle="-")
    plt.title("Comparaison des Loss (Perte)")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()

    # Graphique Mean IoU
    plt.subplot(3, 2, 2)
    for modele, df in resultats.items():
        couleur = couleurs.get(modele, "black")
        if "mean_iou" in df.columns:
            plt.plot(df["mean_iou"], label=f"{modele} Train Mean IoU", color=couleur, linestyle="--")
            plt.plot(df["val_mean_iou"], label=f"{modele} Val Mean IoU", color=couleur, linestyle="-")
        elif "iou_score" in df.columns:
            plt.plot(df["iou_score"], label=f"{modele} Train IoU Score", color=couleur, linestyle="--")
            plt.plot(df["val_iou_score"], label=f"{modele} Val IoU Score", color=couleur, linestyle="-")
    plt.title("Comparaison du Mean IoU / IoU Score")
    plt.xlabel("Epochs")
    plt.ylabel("Mean IoU")
    plt.grid(True)
    plt.legend()

    # Graphique Dice Coefficient
    plt.subplot(3, 2, 3)
    for modele, df in resultats.items():
        couleur = couleurs.get(modele, "black")
        if "dice_coef" in df.columns:
            plt.plot(df["dice_coef"], label=f"{modele} Train Dice", color=couleur, linestyle="--")
            plt.plot(df["val_dice_coef"], label=f"{modele} Val Dice", color=couleur, linestyle="-")
    plt.title("Comparaison du Dice Coefficient")
    plt.xlabel("Epochs")
    plt.ylabel("Dice Coefficient")
    plt.grid(True)
    plt.legend()

    # Graphique Accuracy
    plt.subplot(3, 2, 4)
    for modele, df in resultats.items():
        couleur = couleurs.get(modele, "black")
        if "accuracy" in df.columns:
            plt.plot(df["accuracy"], label=f"{modele} Train Accuracy", color=couleur, linestyle="--")
            plt.plot(df["val_accuracy"], label=f"{modele} Val Accuracy", color=couleur, linestyle="-")
    plt.title("Comparaison de l'Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()

    # Graphique Temps d'entraÃ®nement par modÃ¨le
    plt.subplot(3, 1, 3)
    temps_entrainement = {}
    for modele, df in resultats.items():
        couleur = couleurs.get(modele, "black")
        if "temps_total_sec" in df.columns:
            temps = df["temps_total_sec"].iloc[-1] / 60  # converti en minutes
            temps_entrainement[modele] = temps
            plt.bar(modele, temps, color=couleur)
            plt.text(modele, temps, f"{temps:.2f} min", ha="center", va="bottom")

    plt.title("Comparaison du Temps total d'entraÃ®nement (en minutes)")
    plt.ylabel("Temps (minutes)")
    plt.grid(True, axis="y")

    plt.tight_layout()
    plt.show()